

# 얼굴 탐지
- Haar Cascade
  >> 머신러닝 기반 알고리즘. 사람 얼굴에 대한 Haar 특징을 학습. Haar은 이미지의 특정 영역에서 픽셀 간의 밝기 차이를 기반으로 함. 이 차이는 일반적으로 사람 얼굴 구조와 비슷한 패턴을 보임
- MTCNN
  >> 딥러닝 기반 얼굴 탐지 알고리즘. 얼굴 및 얼굴의 주요 특징 눈, 코, 입을 찾음. P-Net, R-Net,O-Net 3단계를 통해서 정확하게 얼굴 탐지를 함


# 얼굴 인식

# 얼굴 추적
## Optical Flow (광학 흐름)
> 동영상 또는 일련의 이미지에서 객체 또는 카메라의 움직임을 추정하기 위해서 사용되는 컴퓨터 비전 기술. 픽셀 간의 움직임을 분석하여 시각적 표현을 찾는데 사용
- Gunner Farneback 알고리즘
  >> 다항식 확장을 사용하여 이웃 픽셀 간의 상관 관계를 계산. 전체 영상을 고려하는 방법 상대적으로 정확하지만 계산 비용이 높다
- Lucas Kanade 알고리즘
  >> 소규모 움직임을 가정하고, 그 움직임이 이웃 픽셀에도 동일하게 적용된다고 가정. 특정 픽셀 주변의 작은 창을 고려하는 방법으로, 계산 비용이 낮지만 큰 움직임에 대해서는 정확도 낮음


# 화면 전환 감지
- Histogram Comparison
  >> 프레임들 사이의 컬러 히스토그램을 비교하여 씬 체인지를 감지

- Edge Change Ratio
  >> 이미지에서 물체의 경계를 활용하여 분포도의 변화를 계산하여 씬 변경 감지

# HISTORY

얼굴의 좌우 위아래 색의 평균 값을 통해서 밝기 최적화

연속된 영상임을 인지하는 AI 또는 알고리즘을 만들어서 영상에서 얼굴 인식하는 바운더리를 연속적으로 인식하는데 도움을 줄 수 있게

Optical Flow: 이 알고리즘은 연속적인 비디오 프레임 사이에서 픽셀의 움직임을 추적합니다. 이를 통해 얼굴의 움직임을 추적할 수 있습니다.
MeanShift/CamShift: 이 알고리즘은 특정 색상 분포를 가진 물체를 추적하는 데 사용됩니다. 초기에 얼굴 인식을 통해 얼굴의 위치를 파악한 후, 그 색상 분포를 기반으로 얼굴을 계속 추적합니다.
Constrained Local Models (CLM): 이 알고리즘은 얼굴의 형태를 가정하고, 그 형태에 맞게 얼굴 특징점을 추적합니다. 이를 통해 얼굴의 움직임을 추적할 수 있습니다.
Active Appearance Models (AAM) / Active Shape Models (ASM): 이 알고리즘은 얼굴의 외형과 질감을 모델링하고, 이를 기반으로 얼굴을 추적합니다.
Deep Learning-based methods: 최근에는 딥러닝 기반의 얼굴 추적 방법도 많이 연구되고 있습니다. 이런 방법들은 대량의 데이터로 학습된 모델을 사용하여 더욱 정확하게 얼굴을 추적할 수 있습니다.



Wiener Deconvolution: 다양한 블러 유형과 노이즈 수준에 적응할 수 있는 강력한 기법입니다.
Richardson-Lucy Deconvolution: 이 알고리즘은 포아송 노이즈를 가정하며, 다양한 블러 유형에 대해 잘 동작합니다.
Total Variation Deblurring: 이 방법은 노이즈를 효과적으로 제거하면서 세부 사항을 유지하므로, 다양한 유형의 이미지에 적용할 수 있습니다.
Blind Deconvolution: 이 방법은 블러 커널이 알려져 있지 않은 상황에 대해 유용합니다. 블러의 원인이 불분명한 경우에도 사용할 수 있습니다.
Deep Learning Based Methods: 딥러닝 기반의 방법들은 매우 다양한 상황에 적응할 수 있습니다. 신경망은 대량의 데이터로 훈련되며, 이 데이터가 다양한 블러 유형을 포함하면, 신경망은 이러한 다양성을 학습할 수 있습니다.


멀티프로세싱 고민
비디오 재생, 영상 처리 부분을 나누어 처리했으나 생각보다 성능이 좋지 않음. 딥러닝은 한개의 프로세서에서 작동함.
어떻게 해결? 일단 영상처리 부분과 비디오 재생을 최적화 해야 함 -> 정렬기능을 최대한 없애야함
스프링 시큐리티처럼 체인 루틴을 가지는게 좋을 거 같음. 

체인을 단순화하였다. 영상이 끊기는 이유는 역직렬화하는데 시간이 오래걸리기 때문이라 clf 값을 낮췄다. 하지만 이는 많은 프레임을 한번에 전송하지 못한다는 단점이있다
압축을 하여 성능을 조금 쓰더라고 역직렬화 시간을 아낄것인가, 아니면 역직렬화 하는데 시간을 좀 쓸것인가 이 문제다. 이는 압축의 성능과 역직렬화의 시간 사이에서의 조절이 필요하다
어떤 영상을 다룰지 모르기때문에 무손실 압축을 사용할 생각이다. 하지만 그 차이가 크지 않다면 손실 압축을 이용하여 시간을 더 단축시키는 것도 괜찮을 거 같다

멀티프로세서가 제대로 종료되지 않는 문제 <- 아무리 찾아도 원인을 알 수 없었고, terminate() 신호를 보내어 종료하게 함

멀티프로세서의 cfl 값과 프로세서개수, 버프 사이즈로 영상재생이 부드러운지 아닌지가 결정됨. 이를 timer 클래스를 이용하여
연산 평균값으로 가장 최적의 값을 찾으면 될 듯 물론 detectCountNuber도 있음

데이터만을 직렬화 할 것. -> 멤버변수를 제외한 함수는 다른곳에 다시 구현 할 것

프로세서 최적화를 위해 모든 객체 생성은 각각의 프로세서에서만 진행. 객체의 인자로 클래스나 함수 원형을 전달하고 생성은 prepare함수에서 진행

딥러닝은 하나의 프로세서에서 진행되어야 함. 그렇기 때문에 연산과 탐지는 나누어야 함. 거기다 탐지가 종료 된 이후에 딥러닝을 진행해야 할 거 같음. 그래서 동영상 분배 -> 이미지 처리 -> 얼굴 탐지 및 추적 -> 영상 재생. 이렇게 하기로 함

gpu 유틸이 높지 않다. 이는 속도가 매우 느린데 큰 영향을 준다. gpu에 작은 데이터를 자주 주고 받는 것은 좋지 않다고 한다. 이를 해결하기위해 작은 이미지를 큰 이미지로 만들어서 한번에 처리하는 방법을 사용해볼것이다 -> 엄청난 성능 향상이 있었다. 역시 데이터 전송 문제였다

딥러닝을 기본으로 얼굴 탐지를 하되 helper라는 cpu기반 얼굴탐지 알고리즘을 넣어서 정확도와 연산 시간을 줄이자..? 이건 좀 애매하다

정면 얼굴 탐지를 해야한다, 이로 누군지 파악해야한다 

이제 트래커가 문제다. 트래커를 어찌할까 트래커 스킵하고 일단 학습할까? 

일단 트래커는 스킵하고 어느정도 딥러닝 성능이 나와서 학습먼저 진행하려고 한다

이미지의 lazy 연산이 애매한 느낌. 이미지 필터에서 필요한 모든 이미지 변환을 실행하는게 맞는 거 같음. 상수를 받아서 이미지 필터에서 미리 변환하고 넘겨주는 방향으로 진행할 것.

kmeans를 사용했음. 결과가 좋지는 않지만 나름 괜찮음.

얼굴 이미지를 저장하지 말고, 좌표를 저장하는게 좋을 거 같음. 좌표를 저장하고 해당 이미지를 학습할때 영상에서 바로 추출하는 느낌으로 진행 하는게 좋을 듯 또한 Face 객체를 만들어서 prev, next, name 속성을 만들고 연속성을 만들면 될 뜻

현재 해야할 것
  영상 추출 과정 -> 트래킹 얼굴 객체 생성
  얼굴 탐지 과정 -> 트래킹 정보를 이미지가 아닌 좌표값으로 받아오고, index와 해당 index의 영상 좌표값에서 얼굴 추출 후 그 이미지를 학습하는 방향으로 -> 근데 이거는 저장만 그렇게 하고 바로 할때는 이미지를 바로 사용하는게 좋을지도 애매하다
  저장할때는 좌표로하고, 바로 사용할때는 이미지 그대로 사용하는 방법으로 진행하자.

  정리: Face객체로 좌표를 저장하고 빈값으로 next, prev 그리고 인식에서 저장할 name, 프레임 번호인 frame을 붙이고, 일단 트래커를 제외하고 생성. 이걸 imgtable에서 진행. 이후 직렬화 후 저장. -> 인식에서 해당 정보를 load하고 영상을 불러와서 해당 위치를 찾고, 눈,코, 입 위치를 정렬하여 (얼굴색 평균화는 나중에) 해당 이미지를 50by50으로 학습 -> 학습된 정보를 바탕으로 Face객체에 라벨링하고 다시 직렬화 후 저장하든가 바로 재생하든가 

방법1. 얼굴 인식부터 만든다.
방법2. 얼굴 탐지와 트래킹부터 완료하고 gui를 만든다.

현재 트래커 프로세서를 따로 만들고 Face객체를 만듬. 이제 이 정보를 바탕으로 트래킹해야함
모든 프레임에서 얼굴 인식을 진행할때, 각 인식된 곳에서 같은 얼굴인지 알아야하며 가령 인식이 되지 않았다면 연속성을 넣어야 함

모든 프로세서는 연산을 빠르게 하기 위해서는 버퍼를 쓰는게 좋다 -> 버퍼를 일반화하고 모든 프로세서에 저장하자

비디오 분배 -> 트래킹 프로세서 -> 이미지 처리 -> 얼굴 탐지 -> 그리기 및 얼굴 추적 -> 비디오 로더
데이터 전송 단위는 section 전송방법은 Queue 데이터는 Frame

모두 각각의 프로세서로 동작하는 구조로 만들었지만, 유동적으로 독립적인 프로세서로 동작할지 프로세서를 나눌지로 변경했다
기본적으로 버퍼는 쓰레드에서 작동하게 했다.

자 이제 어느정도 기반은 만들었음. 이제 해당 기반을 바탕으로 Controller와 로더 정도만 수정하면 됨
Controller에 2차원배열로 프로세서와 한 프로세서에서 연속적으로 연산할 로직을 추가하면 됨. 여기서 해당 배열과 매칭되는 프로세서 개수 배열도 있어야함
근데 시작 프로세서는 무조건 하나여야 함. 여기서 만약 시작프로세서와 따로 이미지 프로세서가 있다고 치자. 이것과 매칭되는 프로세서 개수를 늘리면 해당 이미지 프로세서의 개수가 늘어나게됨 즉 성능 향상